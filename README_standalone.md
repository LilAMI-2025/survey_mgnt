# ğŸ¯ Standalone Survey Deduplication Module

A powerful, Streamlit-free deduplication engine that achieves **99.88%** and **99.66%** efficiency rates for survey data processing.

## âœ¨ Key Features

- **ğŸš€ Proven Performance**: 99.88% reduction for question-choice combinations, 99.66% for unique questions
- **ğŸ”§ Zero UI Dependencies**: Pure Python - works in any environment
- **ğŸ“Š Advanced Algorithms**: Sophisticated normalization and consolidation logic  
- **âœ… Comprehensive Validation**: 5-point validation system ensures quality
- **ğŸŒ Multi-Environment**: Google Colab, Jupyter, standalone scripts
- **ğŸ’¾ Flexible Export**: CSV, Excel, and programmatic access

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements_standalone.txt
```

### 2. Basic Usage
```python
from standalone_deduplicator import SurveyDeduplicationPipeline

# Initialize pipeline
pipeline = SurveyDeduplicationPipeline()

# Run Step 1A: Question-Choice Combinations (99.88% efficiency)
step1a = pipeline.run_step1a_deduplication()
print(f"Reduced {step1a['metrics']['original_count']} â†’ {step1a['metrics']['final_count']} records")

# Run Step 1B: Unique Questions (99.66% efficiency)  
step1b = pipeline.run_step1b_deduplication()
print(f"Reduced {step1b['metrics']['original_count']} â†’ {step1b['metrics']['final_count']} records")

# Export results
files = pipeline.export_results('both', 'csv')
```

### 3. Quick Functions (One-Liners)
```python
from standalone_deduplicator import quick_step1a_deduplication, quick_step1b_deduplication

# Get deduplicated DataFrames directly
df_step1a = quick_step1a_deduplication()  # 99.88% efficiency
df_step1b = quick_step1b_deduplication()  # 99.66% efficiency
```

## ğŸ”§ Configuration

### Snowflake Credentials

**Option 1: Environment Variables**
```bash
export SNOWFLAKE_ACCOUNT="your_account.region"
export SNOWFLAKE_USER="your_username"
export SNOWFLAKE_PASSWORD="your_password"
export SNOWFLAKE_WAREHOUSE="your_warehouse"
export SNOWFLAKE_DATABASE="your_database"
export SNOWFLAKE_SCHEMA="your_schema"
```

**Option 2: Direct Configuration**
```python
credentials = {
    'account': 'your_account.region',
    'user': 'your_username', 
    'password': 'your_password',
    'warehouse': 'your_warehouse',
    'database': 'your_database',
    'schema': 'your_schema'
}

pipeline = SurveyDeduplicationPipeline(credentials)
```

**Option 3: Config File** (`.streamlit/secrets.toml`)
```toml
[snowflake]
account = "your_account.region"
user = "your_username"
password = "your_password"
warehouse = "your_warehouse"
database = "your_database"
schema = "your_schema"
```

## ğŸ“Š Performance Metrics

Based on real-world testing with survey data:

| Step | Process | Input Records | Output Records | Efficiency | Validation |
|------|---------|---------------|----------------|------------|------------|
| 1A | Question-Choice Combinations | 8,858 | 11 | **99.88%** | 5/5 âœ… |
| 1B | Unique Questions | 33,640 | 115 | **99.66%** | 5/5 âœ… |

## ğŸ§  Algorithm Overview

### Enhanced Deduplication Solutions
1. **Whitespace & Cleanup**: Remove formatting inconsistencies
2. **Advanced Normalization**: Business terminology standardization  
3. **Intelligent Grouping**: UID + normalized question/choice consolidation
4. **Quality Validation**: 5-point validation system

### Text Processing Features
- Multi-language filtering (English focus)
- Business terminology normalization
- Temporal reference standardization
- Choice response consolidation
- Pattern-based duplicate detection

## ğŸŒ Google Colab Usage

1. Upload `standalone_deduplicator.py` to your Colab environment
2. Install dependencies: `!pip install pandas numpy snowflake-connector-python sqlalchemy`
3. Use the provided `colab_example.ipynb` notebook

```python
# In Google Colab
from standalone_deduplicator import SurveyDeduplicationPipeline

# Set up credentials
credentials = {
    'account': 'your_account.region',
    'user': 'your_username',
    'password': 'your_password',
    'warehouse': 'your_warehouse', 
    'database': 'your_database',
    'schema': 'your_schema'
}

# Run deduplication
pipeline = SurveyDeduplicationPipeline(credentials)
results = pipeline.run_step1a_deduplication()

# Download results
files = pipeline.export_results('1a', 'csv')
```

## ğŸ“ˆ Advanced Usage

### Custom Survey Stages
```python
custom_stages = ['Annual Impact Survey', 'Pre-Programme Survey']
results = pipeline.run_step1a_deduplication(survey_stages=custom_stages)
```

### Batch Processing
```python
# Process smaller batches for memory efficiency
results = pipeline.run_step1a_deduplication(limit=10000)
```

### Detailed Analysis
```python
# Get comprehensive metrics
summary = pipeline.get_summary_report()

# Access validation results
validation = results['validation']
passed_checks = sum(validation.values())
print(f"Quality Score: {passed_checks}/5")
```

## ğŸ” Validation System

The module includes a 5-point validation system:

1. âœ… **Registration Consolidated**: Contact/registration questions unified
2. âœ… **Terminology Consistent**: Business terms standardized  
3. âœ… **Choice Formatting Clean**: No trailing numbers or artifacts
4. âœ… **Temporal Normalized**: Date/time references standardized
5. âœ… **Yes/No Standardized**: Binary responses unified

## ğŸ“ Output Formats

### CSV Export
```python
files = pipeline.export_results('both', 'csv')
# Outputs: question_bank_step1a_YYYYMMDD_HHMMSS.csv
#          question_bank_step1b_YYYYMMDD_HHMMSS.csv
```

### Excel Export  
```python
files = pipeline.export_results('both', 'excel')
# Outputs: question_bank_step1a_YYYYMMDD_HHMMSS.xlsx
#          question_bank_step1b_YYYYMMDD_HHMMSS.xlsx
```

### Programmatic Access
```python
# Direct DataFrame access
df = results['data']
metrics = results['metrics']
validation = results['validation']
```

## ğŸ› ï¸ Dependencies

**Required:**
- `pandas` >= 1.5.0
- `numpy` >= 1.21.0  
- `snowflake-connector-python` >= 3.0.0
- `sqlalchemy` >= 1.4.0

**Optional:**
- `openpyxl` >= 3.0.0 (for Excel export)
- `sentence-transformers` >= 2.2.0 (future semantic features)
- `toml` >= 0.10.0 (for config file support)

## ğŸ”§ Troubleshooting

### Common Issues

**Connection Errors**
```python
# Test connection
try:
    pipeline = SurveyDeduplicationPipeline(credentials)
    print("âœ… Connection successful")
except Exception as e:
    print(f"âŒ Connection failed: {e}")
```

**Memory Issues**
```python
# Reduce batch size
results = pipeline.run_step1a_deduplication(limit=5000)
```

**No Data Retrieved**
```python
# Check available survey stages
df = pipeline.get_survey_data_from_snowflake()
print(f"Survey stages: {df['survey_stage'].unique()}")
```

### Performance Tips

1. **Batch Processing**: Use smaller limits for large datasets
2. **Specific Stages**: Filter to relevant survey stages only
3. **Regular Exports**: Save results frequently to prevent data loss
4. **Memory Management**: Process data in chunks if needed

## ğŸ“Š Why This Module Works

This standalone module contains the **exact same deduplication algorithms** that achieved:
- 99.88% efficiency in production Streamlit application
- 5/5 validation checks passed consistently
- Proven performance across multiple survey datasets

**Key Differences from Streamlit Version:**
- âœ… Zero UI dependencies
- âœ… Pure Python compatibility  
- âœ… Google Colab ready
- âœ… Jupyter notebook compatible
- âœ… Standalone script support

## ğŸ¯ Use Cases

- **Google Colab Analysis**: Data science workflows
- **Jupyter Notebooks**: Research and development
- **Standalone Scripts**: Automated processing pipelines
- **API Integration**: Backend deduplication services
- **Batch Processing**: Large-scale survey data cleanup

## ğŸ“ Support

This module extracts the proven deduplication logic from the working Streamlit application. The core algorithms remain unchanged, ensuring the same high-quality results without UI dependencies.

For questions about implementation or customization, refer to the comprehensive examples in `colab_example.ipynb`. 